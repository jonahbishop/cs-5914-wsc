{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.ml.classification import RandomForestClassifier, NaiveBayes, GBTClassifier, LinearSVC, LogisticRegression\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_metrics(bestModel, testData):\n",
    "    lrPredictions = bestModel.transform(testData)\n",
    "    eval_accuracy = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "    eval_precision = MulticlassClassificationEvaluator(metricName=\"precisionByLabel\")\n",
    "    eval_recall = MulticlassClassificationEvaluator(metricName=\"recallByLabel\")\n",
    "    eval_f1 = MulticlassClassificationEvaluator(metricName=\"f1\")\n",
    "\n",
    "    accuracy = eval_accuracy.evaluate(lrPredictions)\n",
    "    precision = eval_precision.evaluate(lrPredictions)\n",
    "    recall = eval_recall.evaluate(lrPredictions)\n",
    "    f1score = eval_f1.evaluate(lrPredictions)\n",
    "\n",
    "    print(f\"Testing Metrics\\nAccuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1 Score: {f1score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_metrics(bestModel, trainingData):\n",
    "    lrPredictions = bestModel.transform(trainingData)\n",
    "    eval_accuracy = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "    eval_precision = MulticlassClassificationEvaluator(metricName=\"precisionByLabel\")\n",
    "    eval_recall = MulticlassClassificationEvaluator(metricName=\"recallByLabel\")\n",
    "    eval_f1 = MulticlassClassificationEvaluator(metricName=\"f1\")\n",
    "\n",
    "    accuracy = eval_accuracy.evaluate(lrPredictions)\n",
    "    precision = eval_precision.evaluate(lrPredictions)\n",
    "    recall = eval_recall.evaluate(lrPredictions)\n",
    "    f1score = eval_f1.evaluate(lrPredictions)\n",
    "\n",
    "    print(f\"Training Metrics\\nAccuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1 Score: {f1score}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractFeatureImp(featureImp, dataset, featuresCol):\n",
    "    list_extract = []\n",
    "    for i in dataset.schema[featuresCol].metadata[\"ml_attr\"][\"attrs\"]:\n",
    "        list_extract = list_extract + dataset.schema[featuresCol].metadata[\"ml_attr\"][\"attrs\"][i]\n",
    "    varlist = pd.DataFrame(list_extract)\n",
    "    varlist['score'] = varlist['idx'].apply(lambda x: featureImp[x])\n",
    "    return(varlist.sort_values('score', ascending = False))\n",
    "\n",
    "# ExtractFeatureImp(featureImportances, trainingData, \"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/29 12:22:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Airline Delay\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", \"true\") \\\n",
    "    .config('spark.driver.memory', '30g') \\\n",
    "    .config('spark.executor.memory', '30g') \\\n",
    "    .getOrCreate()\n",
    "spark.sparkContext.setLogLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "sdf = spark.read.csv('/mydata/wss-project-files/flight-delay-model/data/clean/clean_full.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "merge_sdf = spark.read.csv('/mydata/wss-project-files/flight-delay-model/data/clean/clean_merge_full.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sdf.drop('_c0')\n",
    "    merge_sdf.drop('_c0')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(sdf)\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=sdf.columns[:-1], outputCol=\"features\")\n",
    "\n",
    "final_df = assembler.transform(sdf)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = final_df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "merge_labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(merge_sdf)\n",
    "\n",
    "merge_assembler = VectorAssembler(\n",
    "    inputCols=merge_sdf.columns[:-1], outputCol=\"features\")\n",
    "\n",
    "merge_final_df = merge_assembler.transform(merge_sdf)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(merge_trainingData, merge_testData) = merge_final_df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics\n",
      "Accuracy: 0.5435598729649441\n",
      "Precision: 0.6701962045264254\n",
      "Recall: 0.5255765298607141\n",
      "F1 Score: 0.5504483736860252\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:=================================>                     (39 + 25) / 64]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Metrics\n",
      "Accuracy: 0.5449431060845437\n",
      "Precision: 0.670681275106715\n",
      "Recall: 0.5288123333936081\n",
      "F1 Score: 0.5518394817252527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "nb_classifier = NaiveBayes()\n",
    "nb_paramGrid = (ParamGridBuilder()\\\n",
    "            .addGrid(nb_classifier.modelType, ['multinomial', 'gaussian'])\n",
    "            .build())\n",
    "nb_crossval = CrossValidator(estimator=nb_classifier,\n",
    "                         estimatorParamMaps=nb_paramGrid,\n",
    "                         evaluator=MulticlassClassificationEvaluator(),\n",
    "                         numFolds=3)\n",
    "nb_fitModel = nb_crossval.fit(trainingData)\n",
    "nb_BestModel= nb_fitModel.bestModel\n",
    "training_metrics(nb_BestModel, trainingData)\n",
    "testing_metrics(nb_BestModel, testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multinomial'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_BestModel._java_obj.getModelType()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier()\n",
    "paramGrid = (ParamGridBuilder()\\\n",
    "            .addGrid(rf_classifier.maxDepth, [2, 5, 10])\n",
    "            .addGrid(rf_classifier.maxBins, [5, 10 , 20])\n",
    "            .addGrid(rf_classifier.numTrees,[5, 20, 50])\n",
    "            .build())\n",
    "rf_crossval = CrossValidator(estimator=rf_classifier,\n",
    "                         estimatorParamMaps=paramGrid,\n",
    "                         evaluator=MulticlassClassificationEvaluator(),\n",
    "                         numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rf_fitModel = rf_crossval.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics\n",
      "Accuracy: 0.6473340849889195\n",
      "Precision: 0.6506608242826687\n",
      "Recall: 0.9366082531375007\n",
      "F1 Score: 0.5786964066312357\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1700:==================================>                  (42 + 22) / 64]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Metrics\n",
      "Accuracy: 0.6472048156923647\n",
      "Precision: 0.6506727039615691\n",
      "Recall: 0.935091135963429\n",
      "F1 Score: 0.5795859466296087\n",
      "     idx                              name     score\n",
      "6      6                        CRSDepTime  0.253428\n",
      "51    51  DOT_ID_Reporting_Airline - 19805  0.123497\n",
      "45    45  IATA_CODE_Reporting_Airline - WN  0.118791\n",
      "40    40  IATA_CODE_Reporting_Airline - MQ  0.070471\n",
      "2      2                             Month  0.052469\n",
      "..   ...                               ...       ...\n",
      "180  180                        Dest - LBB  0.000000\n",
      "181  181                        Dest - LBE  0.000000\n",
      "182  182                        Dest - LCH  0.000000\n",
      "183  183                        Dest - LEX  0.000000\n",
      "68    68                        Dest - ACT  0.000000\n",
      "\n",
      "[299 rows x 3 columns]\n",
      "Max Depth: 10\n",
      "Max Bins: 20\n",
      "Num Trees: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rf_BestModel= rf_fitModel.bestModel\n",
    "rf_featureImportances= rf_BestModel.featureImportances.toArray()\n",
    "training_metrics(rf_BestModel, trainingData)\n",
    "testing_metrics(rf_BestModel, testData)\n",
    "print(ExtractFeatureImp(rf_featureImportances, trainingData, \"features\"))\n",
    "print(f'Max Depth: {rf_BestModel._java_obj.getMaxDepth()}')\n",
    "print(f'Max Bins: {rf_BestModel._java_obj.getMaxBins()}')\n",
    "print(f'Num Trees: {rf_BestModel._java_obj.getNumTrees()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_rf_classifier = RandomForestClassifier()\n",
    "merge_rf_paramGrid = (ParamGridBuilder()\\\n",
    "            .addGrid(merge_rf_classifier.maxDepth, [2, 5, 10])\n",
    "            .addGrid(merge_rf_classifier.maxBins, [5, 10 , 20])\n",
    "            .addGrid(merge_rf_classifier.numTrees,[5, 20, 50])\n",
    "            .build())\n",
    "merge_rf_crossval = CrossValidator(estimator=merge_rf_classifier,\n",
    "                         estimatorParamMaps=merge_rf_paramGrid,\n",
    "                         evaluator=MulticlassClassificationEvaluator(),\n",
    "                         numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "merge_rf_fitModel = merge_rf_crossval.fit(merge_trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics\n",
      "Accuracy: 0.6606027181249478\n",
      "Precision: 0.6628219297212584\n",
      "Recall: 0.9313232884122766\n",
      "F1 Score: 0.6023238372127822\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Metrics\n",
      "Accuracy: 0.6583738932925416\n",
      "Precision: 0.6617791275189017\n",
      "Recall: 0.9292943502113766\n",
      "F1 Score: 0.5997096511915421\n",
      "     idx                              name     score\n",
      "6      6                        CRSDepTime  0.197723\n",
      "51    51  DOT_ID_Reporting_Airline - 19805  0.083522\n",
      "298  298                              PRCP  0.051362\n",
      "48    48  DOT_ID_Reporting_Airline - 19393  0.040958\n",
      "296  296                         ELEVATION  0.032215\n",
      "..   ...                               ...       ...\n",
      "176  176                        Dest - KTN  0.000000\n",
      "181  181                        Dest - LBE  0.000000\n",
      "184  184                        Dest - LFT  0.000000\n",
      "187  187                        Dest - LIH  0.000000\n",
      "165  165                        Dest - ILM  0.000000\n",
      "\n",
      "[330 rows x 3 columns]\n",
      "Max Depth: 10\n",
      "Max Bins: 10\n",
      "Max Bins: 5\n"
     ]
    }
   ],
   "source": [
    "merge_rf_BestModel= merge_rf_fitModel.bestModel\n",
    "merge_rf_featureImportances= merge_rf_BestModel.featureImportances.toArray()\n",
    "training_metrics(merge_rf_BestModel, merge_trainingData)\n",
    "testing_metrics(merge_rf_BestModel, merge_testData)\n",
    "print(ExtractFeatureImp(merge_rf_featureImportances, merge_trainingData, \"features\"))\n",
    "print(f'Max Depth: {merge_rf_BestModel._java_obj.getMaxDepth()}')\n",
    "print(f'Max Bins: {merge_rf_BestModel._java_obj.getMaxBins()}')\n",
    "print(f'Max Bins: {merge_rf_BestModel._java_obj.getNumTrees()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_classifier = GBTClassifier()\n",
    "gbt_paramGrid = (ParamGridBuilder()\\\n",
    "            .addGrid(gbt_classifier.maxDepth, [2, 5, 10])\n",
    "            .addGrid(gbt_classifier.maxBins, [5, 10 , 20])\n",
    "            .build())\n",
    "gbt_crossval = CrossValidator(estimator=gbt_classifier,\n",
    "                         estimatorParamMaps=gbt_paramGrid,\n",
    "                         evaluator=MulticlassClassificationEvaluator(),\n",
    "                         numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "gbt_fitModel = gbt_crossval.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_BestModel= gbt_fitModel.bestModel\n",
    "gbt_featureImportances = gbt_BestModel.featureImportances.toArray()\n",
    "training_metrics(gbt_BestModel, trainingData)\n",
    "testing_metrics(gbt_BestModel, testData)\n",
    "print(ExtractFeatureImp(gbt_featureImportances, trainingData, \"features\"))\n",
    "print(f'Max Depth: {gbt_BestModel._java_obj.getMaxDepth()}')\n",
    "print(f'Max Bins: {gbt_BestModel._java_obj.getMaxBins()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Tree Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_gbt_classifier = GBTClassifier()\n",
    "merge_gbt_paramGrid = (ParamGridBuilder()\\\n",
    "            .addGrid(merge_gbt_classifier.maxDepth, [2, 5, 10])\n",
    "            .addGrid(merge_gbt_classifier.maxBins, [5, 10 , 20])\n",
    "            .build())\n",
    "merge_gbt_crossval = CrossValidator(estimator=merge_gbt_classifier,\n",
    "                         estimatorParamMaps=merge_gbt_paramGrid,\n",
    "                         evaluator=MulticlassClassificationEvaluator(),\n",
    "                         numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_gbt_fitModel = merge_gbt_crossval.fit(merge_trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_gbt_BestModel= merge_gbt_fitModel.bestModel\n",
    "merge_gbt_featureImportances= merge_gbt_BestModel.featureImportances.toArray()\n",
    "training_metrics(merge_gbt_BestModel, merge_trainingData)\n",
    "testing_metrics(merge_gbt_BestModel, merge_testData)\n",
    "print(ExtractFeatureImp(merge_gbt_featureImportances, merge_trainingData, \"features\"))\n",
    "print(f'Max Depth: {merge_gbt_BestModel._java_obj.getMaxDepth()}')\n",
    "print(f'Max Bins: {merge_gbt_BestModel._java_obj.getMaxBins()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_classifier = LinearSVC()\n",
    "svc_paramGrid = (ParamGridBuilder()\\\n",
    "            .addGrid(svc_classifier.aggregationDepth, [2, 5, 10])\n",
    "            .addGrid(svc_classifier.maxIter, [50, 100, 200])\n",
    "            .build())\n",
    "svc_crossval = CrossValidator(estimator=svc_classifier,\n",
    "                         estimatorParamMaps=svc_paramGrid,\n",
    "                         evaluator=MulticlassClassificationEvaluator(),\n",
    "                         numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_fitModel = svc_crossval.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_BestModel= svc_fitModel.bestModel\n",
    "training_metrics(svc_BestModel, trainingData)\n",
    "testing_metrics(svc_BestModel, testData)\n",
    "print(f'Aggregation Depth: {svc_BestModel._java_obj.getAggregationDepth()}')\n",
    "print(f'Max Iterations: {svc_BestModel._java_obj.getMaxIter()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVC Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_svc_classifier = LinearSVC()\n",
    "merge_svc_paramGrid = (ParamGridBuilder()\\\n",
    "            .addGrid(svc_classifier.aggregationDepth, [2, 5, 10])\n",
    "            .addGrid(svc_classifier.maxIter, [10, 50, 100])\n",
    "            .build())\n",
    "merge_svc_crossval = CrossValidator(estimator=merge_svc_classifier,\n",
    "                         estimatorParamMaps=merge_svc_paramGrid,\n",
    "                         evaluator=MulticlassClassificationEvaluator(),\n",
    "                         numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_svc_fitModel = merge_svc_crossval.fit(merge_trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_svc_BestModel= merge_svc_fitModel.bestModel\n",
    "training_metrics(merge_svc_BestModel, merge_trainingData)\n",
    "testing_metrics(merge_svc_BestModel, merge_testData)\n",
    "print(f'Aggregation Depth: {merge_svc_BestModel._java_obj.getAggregationDepth()}')\n",
    "print(f'Max Iterations: {merge_svc_BestModel._java_obj.getMaxIter()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_classifier = LogisticRegression()\n",
    "lr_paramGrid = (ParamGridBuilder()\\\n",
    "            .addGrid(lr_classifier.regParam, [0.01, 0.5, 2.0])\n",
    "            .addGrid(lr_classifier.maxIter, [10, 50, 100])\n",
    "            .addGrid(lr_classifier.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "            .build())\n",
    "lr_crossval = CrossValidator(estimator=lr_classifier,\n",
    "                         estimatorParamMaps=lr_paramGrid,\n",
    "                         evaluator=MulticlassClassificationEvaluator(),\n",
    "                         numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_fitModel = lr_crossval.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_BestModel= lr_fitModel.bestModel\n",
    "training_metrics(lr_BestModel, trainingData)\n",
    "testing_metrics(lr_BestModel, testData)\n",
    "print(f'Reg Param: {lr_BestModel._java_obj.getRegParam()}')\n",
    "print(f'Max Iterations: {lr_BestModel._java_obj.getMaxIter()}')\n",
    "print(f'Elastic Net Param: {lr_BestModel._java_obj.getElasticNetParam()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_lr_classifier = LogisticRegression()\n",
    "merge_lr_paramGrid = (ParamGridBuilder()\\\n",
    "            .addGrid(merge_lr_classifier.regParam, [0.01, 0.5, 2.0])\n",
    "            .addGrid(merge_lr_classifier.maxIter, [10, 50, 100])\n",
    "            .addGrid(merge_lr_classifier.elasticNetParam, [0.0, 0.5, 1.0])\n",
    "            .build())\n",
    "merge_lr_crossval = CrossValidator(estimator=merge_lr_classifier,\n",
    "                         estimatorParamMaps=merge_lr_paramGrid,\n",
    "                         evaluator=MulticlassClassificationEvaluator(),\n",
    "                         numFolds=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_lr_fitModel = merge_lr_crossval.fit(merge_trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_lr_BestModel= merge_lr_fitModel.bestModel\n",
    "training_metrics(merge_lr_BestModel, merge_trainingData)\n",
    "testing_metrics(merge_lr_BestModel, merge_testData)\n",
    "print(f'Reg Param: {merge_lr_BestModel._java_obj.getRegParam()}')\n",
    "print(f'Max Iterations: {merge_lr_BestModel._java_obj.getMaxIter()}')\n",
    "print(f'Elastic Net Param: {merge_lr_BestModel._java_obj.getElasticNetParam()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "c07d2e75d0ea529b7f507ad4ca95a3bde5feb9750d77ae84c4d0e69865b98310"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
